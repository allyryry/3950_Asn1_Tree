{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "##Seaborn for fancy plots. \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3950 Assignment 1: Part 2\n",
    "\n",
    "For this assignment we want to use some sort of tree based model to classify the data below. We have a very small training set, so overfitting is a very real concern. \n",
    "\n",
    "Some specifics for this assignment:\n",
    "<ul>\n",
    "<li>Please paste in any outside functions you may use before submitting. E.g. if you're importing any functions from a util file, paste them in here for this. The reason for this is that it makes it massively easier for me when downloading a submission from everyone. Please put the blocks with those functions before they're called, so I can hit Run All to run the entire workbook. \n",
    "<li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "      <th>var_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  var_1  var_2  var_3  var_4  var_5  var_6  var_7  var_8  var_9  \\\n",
       "216       1  0.417  0.362  0.084  0.182  0.281  0.244  0.266  0.400  0.582   \n",
       "53        0  0.089  0.392  0.351  0.807  0.627  0.040  0.869  0.119  0.343   \n",
       "121       0  0.536  0.905  0.252  0.787  0.642  0.129  0.196  0.353  0.003   \n",
       "52        0  0.140  0.667  0.745  0.472  0.598  0.735  0.462  0.802  0.405   \n",
       "3         0  0.681  0.245  0.909  0.785  0.738  0.570  0.692  0.411  0.182   \n",
       "173       0  0.443  0.999  0.527  0.291  0.140  0.608  0.848  0.132  0.454   \n",
       "78        1  0.223  0.513  0.924  0.788  0.092  0.925  0.876  0.618  0.790   \n",
       "210       0  0.782  0.908  0.520  0.649  0.557  0.385  0.934  0.124  0.229   \n",
       "104       1  0.706  0.219  0.331  0.979  0.274  0.117  0.093  0.584  0.038   \n",
       "81        1  0.028  0.706  0.018  0.984  0.564  0.831  0.697  0.032  0.414   \n",
       "\n",
       "     ...  var_191  var_192  var_193  var_194  var_195  var_196  var_197  \\\n",
       "216  ...    0.630    0.592    0.659    0.037    0.852    0.501    0.462   \n",
       "53   ...    0.774    0.484    0.508    0.412    0.458    0.981    0.616   \n",
       "121  ...    0.632    0.062    0.324    0.319    0.677    0.508    0.492   \n",
       "52   ...    0.435    0.729    0.588    0.225    0.362    0.740    0.430   \n",
       "3    ...    0.219    0.691    0.261    0.031    0.968    0.353    0.798   \n",
       "173  ...    0.882    0.236    0.031    0.512    0.155    0.904    0.813   \n",
       "78   ...    0.805    0.268    0.024    0.761    0.221    0.767    0.539   \n",
       "210  ...    0.697    0.212    0.334    0.402    0.580    0.839    0.872   \n",
       "104  ...    0.080    0.657    0.220    0.080    0.542    0.967    0.445   \n",
       "81   ...    0.085    0.511    0.551    0.914    0.061    0.850    0.977   \n",
       "\n",
       "     var_198  var_199  var_200  \n",
       "216    0.290    0.357    0.437  \n",
       "53     0.539    0.977    0.979  \n",
       "121    0.546    0.051    0.470  \n",
       "52     0.329    0.411    0.766  \n",
       "3      0.104    0.944    0.090  \n",
       "173    0.054    0.117    0.509  \n",
       "78     0.424    0.859    0.227  \n",
       "210    0.778    0.735    0.779  \n",
       "104    0.193    0.096    0.885  \n",
       "81     0.557    0.624    0.935  \n",
       "\n",
       "[10 rows x 201 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"training.csv\")\n",
    "df = df.drop(columns={\"id\"})\n",
    "df[\"target\"] = df[\"target\"].astype(\"int32\")\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target     0\n",
       "var_138    0\n",
       "var_128    0\n",
       "var_129    0\n",
       "var_130    0\n",
       "          ..\n",
       "var_70     0\n",
       "var_71     0\n",
       "var_72     0\n",
       "var_73     0\n",
       "var_200    0\n",
       "Length: 201, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing\n",
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a trial run to see what a default forrest looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5733333333333334\n",
      "Avg Depth: 8.22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_trial = np.array(df[\"target\"]).reshape(-1,1)\n",
    "X_trial = np.array(df.drop(columns={\"target\"}))\n",
    "X_trainT, X_testT, y_trainT, y_testT = train_test_split(X_trial, y_trial.ravel(), test_size=.3)\n",
    "\n",
    "trial_forrest = RandomForestClassifier()\n",
    "trial_pipe = [('scale', StandardScaler()),('forest', trial_forrest) ]\n",
    "pipe = Pipeline(trial_pipe)\n",
    "# The pipeline can be used as any other estimator\n",
    "# and avoids leaking the test set into the train set\n",
    "pipe.fit(X_trainT, y_trainT)\n",
    "print(\"Score:\", pipe.score(X_testT, y_testT))\n",
    "trial_depths = [estimator.tree_.max_depth for estimator in trial_forrest.estimators_]\n",
    "print(\"Avg Depth:\", np.mean(trial_depths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model using grid search to tune HPs. The training set is very small, so calculation of many options should be pretty fast. \n",
    "\n",
    "I'm going to scale the data, but I suspect that will not be a massive impact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Pipeline with Scaling. \n",
    "scaler = StandardScaler()\n",
    "estimator = RandomForestClassifier(n_jobs=-1, verbose=0)\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"forrest\", estimator)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post grid\n",
      "post fit\n",
      "post best\n",
      "0.6533333333333333\n",
      "post score\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_trial, y_trial.ravel(), test_size=.3)\n",
    "\n",
    "rf_para = {'forrest__min_samples_split':[3,4,5,6,7,8,9,10],\n",
    "#            'forrest__criterion':[\"gini\",\"entropy\"],\n",
    "            'forrest__max_depth':[5,6,7,8,9],\n",
    "            'forrest__n_estimators':[100,150,175],\n",
    "            'forrest__max_samples':[.4, .5, .6, .7]}\n",
    "#            'forrest_max_features':[100,120,140,160,180,199]}\n",
    "\n",
    "#rf_para = {'forrest__max_depth':[3,4,5,6,7,8,9]}\n",
    " \n",
    "clf = GridSearchCV(pipe, param_grid=rf_para, cv=10, n_jobs=-1) \n",
    "print(\"post grid\")\n",
    "clf.fit(X_train, y_train.ravel())\n",
    "print(\"post fit\")\n",
    "best = clf.best_estimator_\n",
    "print(\"post best\")\n",
    "print(best.score(X_test, y_test))\n",
    "print(\"post score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n"
     ]
    }
   ],
   "source": [
    "print(best.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "Please leave the stuff below as-is in your file. \n",
    "\n",
    "This will take your best model and score it with the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Test Data\n",
    "test_df = pd.read_csv(\"testing.csv\")\n",
    "test_df[\"id\"] = test_df[\"id\"].astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88521246 0.8699046  0.86946671 0.88331467 0.86870119]\n",
      "0.6247088607594937\n"
     ]
    }
   ],
   "source": [
    "#Create tests and score\n",
    "test_y = np.array(test_df[\"target\"]).reshape(-1,1)\n",
    "test_X = np.array(test_df.drop(columns={\"id\",\"target\"}))\n",
    "print(cross_val_score(best, test_X, test_y.ravel(), cv=5, scoring='roc_auc'))\n",
    "print(best.score(test_X,test_y))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml3950': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
