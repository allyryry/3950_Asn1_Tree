{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "##Seaborn for fancy plots. \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3950 Assignment 1: Part 2\n",
    "\n",
    "For this assignment we want to use some sort of tree based model to classify the data below. We have a very small training set, so overfitting is a very real concern. \n",
    "\n",
    "Some specifics for this assignment:\n",
    "<ul>\n",
    "<li>Please paste in any outside functions you may use before submitting. E.g. if you're importing any functions from a util file, paste them in here for this. The reason for this is that it makes it massively easier for me when downloading a submission from everyone. Please put the blocks with those functions before they're called, so I can hit Run All to run the entire workbook. \n",
    "<li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>1.641</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>1.656</td>\n",
       "      <td>0.694</td>\n",
       "      <td>-0.763</td>\n",
       "      <td>-1.388</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.280</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.641</td>\n",
       "      <td>0.684</td>\n",
       "      <td>1.669</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.558</td>\n",
       "      <td>-0.805</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-1.719</td>\n",
       "      <td>1.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>1.207</td>\n",
       "      <td>0.407</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.229</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>1.030</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.280</td>\n",
       "      <td>1.208</td>\n",
       "      <td>0.870</td>\n",
       "      <td>-0.774</td>\n",
       "      <td>-1.211</td>\n",
       "      <td>-1.056</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.765</td>\n",
       "      <td>-0.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1.256</td>\n",
       "      <td>1.212</td>\n",
       "      <td>-0.433</td>\n",
       "      <td>-1.691</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.293</td>\n",
       "      <td>0.780</td>\n",
       "      <td>1.082</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-1.027</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.144</td>\n",
       "      <td>1.069</td>\n",
       "      <td>1.391</td>\n",
       "      <td>-0.459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.624</td>\n",
       "      <td>1.721</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>1.126</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.335</td>\n",
       "      <td>-0.570</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.527</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>1.108</td>\n",
       "      <td>0.154</td>\n",
       "      <td>-0.579</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>0.359</td>\n",
       "      <td>-1.959</td>\n",
       "      <td>0.463</td>\n",
       "      <td>-0.653</td>\n",
       "      <td>-1.498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.836</td>\n",
       "      <td>-1.430</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-2.313</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.501</td>\n",
       "      <td>-1.960</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-1.467</td>\n",
       "      <td>-1.011</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.337</td>\n",
       "      <td>-1.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.276</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.798</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.631</td>\n",
       "      <td>-0.835</td>\n",
       "      <td>-2.228</td>\n",
       "      <td>-0.583</td>\n",
       "      <td>-0.396</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>0.366</td>\n",
       "      <td>2.329</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.908</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>1.005</td>\n",
       "      <td>0.687</td>\n",
       "      <td>-0.925</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>2.307</td>\n",
       "      <td>0.892</td>\n",
       "      <td>-0.648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.843</td>\n",
       "      <td>-0.832</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-1.669</td>\n",
       "      <td>0.718</td>\n",
       "      <td>1.842</td>\n",
       "      <td>0.224</td>\n",
       "      <td>1.099</td>\n",
       "      <td>0.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.479</td>\n",
       "      <td>0.635</td>\n",
       "      <td>-2.967</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.324</td>\n",
       "      <td>1.198</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>1.555</td>\n",
       "      <td>0.375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.180</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.990</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>-1.525</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.374</td>\n",
       "      <td>1.004</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.133</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>-1.912</td>\n",
       "      <td>-1.010</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-0.934</td>\n",
       "      <td>-0.365</td>\n",
       "      <td>-0.836</td>\n",
       "      <td>...</td>\n",
       "      <td>1.950</td>\n",
       "      <td>-0.712</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>1.682</td>\n",
       "      <td>1.945</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>-1.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>1.157</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>-0.379</td>\n",
       "      <td>0.620</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>-1.921</td>\n",
       "      <td>-0.389</td>\n",
       "      <td>-0.872</td>\n",
       "      <td>0.885</td>\n",
       "      <td>1.297</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target      0      1      2      3      4      5      6      7      8  \\\n",
       "183       0 -0.079  1.641 -0.209  1.656  0.694 -0.763 -1.388  0.921  0.280   \n",
       "114       0  1.207  0.407 -0.087  0.229 -0.682  1.030  0.053  0.628  0.388   \n",
       "23        0  1.256  1.212 -0.433 -1.691  0.046 -0.293  0.780  1.082 -0.404   \n",
       "20        0 -1.624  1.721 -0.175  1.126  0.051  0.335 -0.570  0.849  0.527   \n",
       "5         0  0.739  0.211 -0.836 -1.430 -0.291 -0.989  0.091  0.107 -2.313   \n",
       "215       0 -0.765 -0.215  0.276 -0.022 -0.505 -0.116 -0.137 -0.141  0.798   \n",
       "74        1 -1.908 -0.374  1.005  0.687 -0.925 -0.605  2.307  0.892 -0.648   \n",
       "94        0 -1.479  0.635 -2.967 -0.046 -0.324  1.198 -0.188  1.555  0.375   \n",
       "178       0 -2.133 -0.204 -0.280 -1.912 -1.010  0.118 -0.934 -0.365 -0.836   \n",
       "44        1  1.157 -0.013 -0.106 -0.379  0.620 -0.442 -0.022  0.536  0.003   \n",
       "\n",
       "     ...    290    291    292    293    294    295    296    297    298    299  \n",
       "183  ... -0.641  0.684  1.669  0.009 -0.558 -0.805 -0.350 -0.127 -1.719  1.557  \n",
       "114  ...  0.154  0.280  1.208  0.870 -0.774 -1.211 -1.056 -0.076  0.765 -0.335  \n",
       "23   ...  0.446 -0.081 -1.027  0.034  0.891  0.322  0.144  1.069  1.391 -0.459  \n",
       "20   ... -0.139  1.108  0.154 -0.579 -0.279  0.359 -1.959  0.463 -0.653 -1.498  \n",
       "5    ... -1.501 -1.960  0.671  0.091 -1.467 -1.011 -0.118 -0.257 -0.337 -1.064  \n",
       "215  ... -1.631 -0.835 -2.228 -0.583 -0.396 -0.464  0.366  2.329  0.946  0.401  \n",
       "74   ...  0.556  0.843 -0.832 -0.046 -1.669  0.718  1.842  0.224  1.099  0.664  \n",
       "94   ...  1.180  0.494  0.990 -0.038 -1.525  0.465  0.374  1.004 -0.319  0.326  \n",
       "178  ...  1.950 -0.712 -0.047  1.682  1.945  0.700  0.089  0.084 -0.222 -1.396  \n",
       "44   ...  0.073  0.032 -0.063 -0.227 -1.921 -0.389 -0.872  0.885  1.297  0.033  \n",
       "\n",
       "[10 rows x 301 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df = df.drop(columns={\"id\"})\n",
    "df[\"target\"] = df[\"target\"].astype(\"int32\")\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id     0\n",
       "205    0\n",
       "203    0\n",
       "202    0\n",
       "201    0\n",
       "      ..\n",
       "98     0\n",
       "97     0\n",
       "96     0\n",
       "95     0\n",
       "299    0\n",
       "Length: 302, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing\n",
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a trial run to see what a default forrest looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7066666666666667\n",
      "Avg Depth: 8.74\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_trial = np.array(df[\"target\"]).reshape(-1,1)\n",
    "X_trial = np.array(df.drop(columns={\"target\"}))\n",
    "X_trainT, X_testT, y_trainT, y_testT = train_test_split(X_trial, y_trial.ravel(), test_size=.3)\n",
    "\n",
    "trial_forrest = RandomForestClassifier()\n",
    "trial_pipe = [('scale', StandardScaler()),('forest', trial_forrest) ]\n",
    "pipe = Pipeline(trial_pipe)\n",
    "# The pipeline can be used as any other estimator\n",
    "# and avoids leaking the test set into the train set\n",
    "pipe.fit(X_trainT, y_trainT)\n",
    "print(\"Score:\", pipe.score(X_testT, y_testT))\n",
    "trial_depths = [estimator.tree_.max_depth for estimator in trial_forrest.estimators_]\n",
    "print(\"Avg Depth:\", np.mean(trial_depths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model using grid search to tune HPs. The training set is very small, so calculation of many options should be pretty fast. \n",
    "\n",
    "I'm going to scale the data, but I suspect that will not be a massive impact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Pipeline with Scaling. \n",
    "scaler = StandardScaler()\n",
    "estimator = RandomForestClassifier(n_jobs=-1)\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"forrest\", estimator)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_trial, y_trial.ravel(), test_size=.3)\n",
    "\n",
    "rf_para = {'forrest__min_samples_split':[3,4,5,6,7,8,9,10,11,12],\n",
    "            'forrest__criterion':[\"gini\",\"entropy\"],\n",
    "            'forrest__max_depth':[3,4,5,6,7,8,9],\n",
    "            'forrest__n_estimators':[50,75,100,125,150,175,200],\n",
    "            'forrest__max_samples':[.4, .5, .6, .7]}\n",
    "\n",
    "#rf_para = {'forrest__max_depth':[3,4,5,6,7,8,9]}\n",
    " \n",
    "clf = GridSearchCV(pipe, param_grid=rf_para, cv=10, n_jobs=-1) \n",
    "clf.fit(X_train, y_train.ravel())\n",
    "best = clf.best_estimator_\n",
    "best.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please leave this as is at the end of your file. \n",
    "# best should be your final trained model. \n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_y = np.array(test_df[\"target\"]).reshape(-1,1)\n",
    "test_X = np.array(test_df.drop(columns={\"target\"}))\n",
    "print(best.score(test_X, test_y.ravel()))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml3950': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
